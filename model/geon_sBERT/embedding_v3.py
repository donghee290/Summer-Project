# kosimcse_direct_embedder.py
from sentence_transformers import SentenceTransformer
import json
import numpy as np
from tqdm import tqdm

def embed_with_original_kosimcse():
    print("ğŸš€ Pythonìœ¼ë¡œ ì›ë³¸ KoSimCSE ì‚¬ìš©")
    
    # ì›ë³¸ KoSimCSE ëª¨ë¸ ì§ì ‘ ë¡œë“œ
    try:
        model = SentenceTransformer('BM-K/KoSimCSE-roberta-multitask')
        print("âœ… ì›ë³¸ KoSimCSE ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
        print(f"   ì°¨ì›: {model.get_sentence_embedding_dimension()}")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ
    print("\nğŸ“Š ë‰´ìŠ¤ ë°ì´í„° ë¡œë”©...")
    with open('source/v3_naver_news_cleaned_1hour_2025-07-29T02-19-57-117Z.json', 'r', encoding='utf-8') as f:
        news_data = json.load(f)
    
    # ê¸°ì‚¬ ì „ì²˜ë¦¬
    articles = []
    category_stats = {}
    
    for category, article_list in news_data['news'].items():
        if not isinstance(article_list, list):
            continue
            
        for article in article_list:
            title = article.get('title', '')
            content = article.get('content', '')
            full_text = f"{title}. {content}".strip()
            
            if len(full_text) > 100 and len(title) > 10:
                articles.append({
                    **article,
                    'fullText': full_text,
                    'textLength': len(full_text),
                    'category': category,
                    'index': len(articles)
                })
                category_stats[category] = category_stats.get(category, 0) + 1
    
    print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {len(articles)}ê°œ ê¸°ì‚¬")
    print("ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
    for cat, count in category_stats.items():
        print(f"   {cat}: {count}ê°œ")
    
    # KoSimCSE ì„ë² ë”© ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬)
    print(f"\nâš¡ KoSimCSE ì„ë² ë”© ìƒì„± ì¤‘...")
    texts = [article['fullText'] for article in articles]
    
    # ë°°ì¹˜ í¬ê¸° ì¡°ì • (ë©”ëª¨ë¦¬ ìµœì í™”)
    batch_size = 32
    embeddings = model.encode(
        texts,
        batch_size=batch_size,
        show_progress_bar=True,
        convert_to_numpy=True,
        normalize_embeddings=True  # SimCSE í‘œì¤€
    )
    
    print(f"âœ… ì„ë² ë”© ì™„ë£Œ! í˜•íƒœ: {embeddings.shape}")
    
    # ê²°ê³¼ ì €ì¥ (JavaScript í˜¸í™˜ í˜•ì‹)
    result = {
        'articles': articles,
        'embeddings': embeddings.tolist(),
        'metadata': {
            'model': 'BM-K/KoSimCSE-roberta-multitask',
            'embedding_method': 'SimCSE',
            'dimensions': int(embeddings.shape[1]),
            'totalArticles': len(articles),
            'createdAt': '2025-08-01T15:00:00.000Z',
            'categories': category_stats,
            'preprocessing': 'kosimcse_python',
            'version': '4.0'
        }
    }
    
    # JSON ì €ì¥
    with open('kosimcse_python_embeddings.json', 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    print("âœ… kosimcse_python_embeddings.json ì €ì¥")
    
    # CSV ì €ì¥ (í´ëŸ¬ìŠ¤í„°ë§ìš©)
    import pandas as pd
    
    csv_data = []
    for i, article in enumerate(articles):
        csv_data.append({
            'index': i,
            'title': article['title'].replace('"', '""'),
            'category': article['category'],
            'textLength': article['textLength'],
            'embedding': ','.join(map(str, embeddings[i])),
            'pubDate': article.get('pubDate', ''),
            'url': article.get('originalUrl', '')
        })
    
    df = pd.DataFrame(csv_data)
    df.to_csv('kosimcse_python_embeddings.csv', index=False, encoding='utf-8')
    print("âœ… kosimcse_python_embeddings.csv ì €ì¥")
    
    # ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ§ª KoSimCSE ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸")
    test_queries = ['ê²½ì œ', 'ì‚¬íšŒ', 'ì—°ì˜ˆ']
    
    for query in test_queries:
        query_embedding = model.encode([query], normalize_embeddings=True)[0]
        similarities = np.dot(embeddings, query_embedding)
        
        top_indices = np.argsort(similarities)[-3:][::-1]
        print(f"\n'{query}' ìœ ì‚¬ ê¸°ì‚¬:")
        for i, idx in enumerate(top_indices):
            print(f"  {i+1}. [{similarities[idx]:.4f}] {articles[idx]['title'][:50]}...")
    
    print(f"\nğŸ¯ ì™„ë£Œ! ë‹¤ìŒ ë‹¨ê³„: python improved_clustering.py")
    return result

if __name__ == "__main__":
    embed_with_original_kosimcse()

